{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.metrics import MAPE\n",
    "from tensorflow.keras import callbacks\n",
    "from google.cloud import storage\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_sequence(df, length):\n",
    "    '''\n",
    "    function that return a random slice of features and targets\n",
    "    len(X) = lenght and len(y) = 3\n",
    "    '''\n",
    "    last_possible = df.shape[0] - length - 3\n",
    "    random_start = np.random.randint(0, last_possible)\n",
    "    X = df[random_start: random_start+length].values\n",
    "    y = df.iloc[random_start+length:random_start+length+3][['price_usd']]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(df, length_of_observations):\n",
    "    '''\n",
    "    function that returns a list of random slices of features and targets\n",
    "    len(X[0]) = lenght and len(y[0]) = 3\n",
    "    '''\n",
    "    X, y = [], []\n",
    "    for length in length_of_observations:\n",
    "        xi, yi = subsample_sequence(df, length)\n",
    "        X.append(xi)\n",
    "        y.append(yi)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tr_te(df, horizon=3, ratio=0.95):\n",
    "    '''\n",
    "    function that returns a training and test set\n",
    "    arguments are:\n",
    "    the horizon of prediction\n",
    "    the ratio of the train/test split\n",
    "    '''\n",
    "    # the gap to avoid data leakage\n",
    "    # gap = horizon - 1\n",
    "    # len_ = int(ratio*df.shape[0])\n",
    "    # data_train = df[:len_]\n",
    "    # data_test = df[len_+gap:]\n",
    "    # return data_train, data_test\n",
    "    \n",
    "    len_ = int(ratio*df.shape[0])\n",
    "    data_train = df[:len_]\n",
    "    data_test = df[len_+1:]\n",
    "    return data_train, data_test\n",
    "    \n",
    "    # len_ = 1696\n",
    "    # data_train = df[:len_]\n",
    "    # data_test = df[len_:]\n",
    "    # return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xy_tr_te(train,\n",
    "                     test,\n",
    "                     train_splits = 3000,\n",
    "                     train_time_min = 30,\n",
    "                     train_time_max = 180):\n",
    "    '''\n",
    "    function returns a serie of train and test data\n",
    "    train splits is the number of selections of our dataset\n",
    "    train_time_min is the minimum number of days that are randomly choosen by the get_X_y function\n",
    "    train_time_max is the maximum number of days that are randomly choosen by the get_X_y function\n",
    "    '''\n",
    "    length_of_observations = np.random.randint(train_time_min, train_time_max, train_splits)\n",
    "    X_train, y_train = get_X_y(train, length_of_observations)\n",
    "    #length_of_observations = np.random.randint(train_time_min, train_time_max, train_splits)\n",
    "    #X_test, y_test = get_X_y(test, length_of_observations)\n",
    "    return X_train, y_train #, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_seq(train):\n",
    "    '''\n",
    "    function that return the padded version of the train dataset\n",
    "    to uniform the size of the model imput\n",
    "    '''\n",
    "    return pad_sequences(train, dtype='float32', value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(X_train_pad, y_train):\n",
    "    '''\n",
    "    function that return a trained baseline model and its fitting history\n",
    "    and save locally the trained model file basemodel.joblib\n",
    "    '''\n",
    "    normalizer = Normalization()\n",
    "    normalizer.adapt(X_train_pad)\n",
    "    model = Sequential()\n",
    "    model.add(normalizer)\n",
    "    model.add(layers.Masking(mask_value=-1))\n",
    "    model.add(layers.LSTM(40, activation='tanh')) # GS N UNITS\n",
    "    model.add(layers.Dense(40, activation='relu')) # GS N UNITS\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=RMSprop(learning_rate=0.01), metrics=MAPE)\n",
    "    es = callbacks.EarlyStopping(patience=6, restore_best_weights=True)\n",
    "    history = model.fit(X_train_pad,\n",
    "                np.array(y_train),\n",
    "                epochs=30,\n",
    "                batch_size=64,\n",
    "                validation_split=0.3,\n",
    "                callbacks=[es],\n",
    "                verbose=1)\n",
    "    joblib.dump(model, 'basemodel.joblib')\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    '''\n",
    "    return the loss and metric plots of train and test fit process\n",
    "    '''\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label = 'train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label = 'val' + exp_name)\n",
    "    ax1.set_ylim(0., 100000)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['mean_absolute_percentage_error'], label='train mape'  + exp_name)\n",
    "    ax2.plot(history.history['val_mean_absolute_percentage_error'], label='val mape'  + exp_name)\n",
    "    ax1.set_ylim(0., 100000)\n",
    "    ax2.set_title('mape')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_3d_price(model, test):\n",
    "    '''\n",
    "    return the prediction of three days after the test data\n",
    "    '''\n",
    "    return model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning of Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.metrics import MAPE\n",
    "from tensorflow.keras import callbacks\n",
    "from google.cloud import storage\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../raw_data/data_advanced.csv', index_col = 'datetime') # TO RUN LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, nb_sequences=2000, nb_days=21, plot_history=False):\n",
    "\n",
    "    data.shape\n",
    "    # data.set_index('datetime', inplace=True)\n",
    "    # for x in data.columns:\n",
    "    #     if x == 'Unnamed: 0':\n",
    "    #         data.drop(columns = x, inplace=True)\n",
    "\n",
    "    # Beginning of test set\n",
    "    y_test = np.resize(np.array(data.tail(3)['price_usd']), (3, 1))\n",
    "    data = data[:-3]\n",
    "    X_test = data.tail(80)\n",
    "\n",
    "    ratio=0.95\n",
    "    len_ = int(ratio*data.shape[0])\n",
    "    data_train = data[:len_]\n",
    "    # data_test = data[len_+1:]\n",
    "\n",
    "    train = data_train\n",
    "    # test = data_test \n",
    "    \n",
    "    train_splits = 3000\n",
    "    train_time_min = 30\n",
    "    train_time_max = 180\n",
    "    length_of_observations = np.random.randint(train_time_min, train_time_max, train_splits)\n",
    "\n",
    "    def subsample_sequence(df, length):\n",
    "        last_possible = df.shape[0] - length - 3\n",
    "        random_start = np.random.randint(0, last_possible)\n",
    "        X = df[random_start: random_start+length].values\n",
    "        y = df.iloc[random_start+length:random_start+length+3][['price_usd']]\n",
    "        return X, y\n",
    "\n",
    "    X, y = [], []\n",
    "    for length in length_of_observations:\n",
    "        xi, yi = subsample_sequence(data, length)\n",
    "        X.append(xi)\n",
    "        y.append(yi)\n",
    "    \n",
    "\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "\n",
    "    \n",
    "    X_train_pad = pad_sequences(X_train, dtype='float32', value=-1)\n",
    "\n",
    "\n",
    "    normalizer = Normalization()\n",
    "    normalizer.adapt(X_train_pad)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(normalizer)\n",
    "    model.add(layers.Masking(mask_value=-1))\n",
    "    model.add(layers.LSTM(40, activation='tanh')) # GS N UNITS\n",
    "    model.add(layers.Dense(40, activation='relu')) # GS N UNITS\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse', \n",
    "                optimizer=RMSprop(learning_rate=0.01), \n",
    "                metrics=MAPE)\n",
    "\n",
    "\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train_pad,\n",
    "                np.array(y_train),\n",
    "                epochs=30,\n",
    "                batch_size=64,\n",
    "                validation_split=0.3,\n",
    "                callbacks=[es],\n",
    "                verbose=1)\n",
    "\n",
    "    if plot_history:\n",
    "        plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "        plt.plot(history.history['val_mean_absolute_percentage_error'])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = (((y_test - y_pred)**2).mean())**0.5\n",
    "    # res = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_usd</th>\n",
       "      <th>volume_usd</th>\n",
       "      <th>twitter_followers</th>\n",
       "      <th>daily_opening_price_usd</th>\n",
       "      <th>daily_high_price_usd</th>\n",
       "      <th>daily_low_price_usd</th>\n",
       "      <th>daily_closing_price_usd</th>\n",
       "      <th>daily_avg_price_usd</th>\n",
       "      <th>daily_trading_volume_usd</th>\n",
       "      <th>marketcap_usd</th>\n",
       "      <th>...</th>\n",
       "      <th>eth_NFT_buyers</th>\n",
       "      <th>total_NFT_sales</th>\n",
       "      <th>total_NFT_buyers</th>\n",
       "      <th>total_TVL</th>\n",
       "      <th>eth_TVL</th>\n",
       "      <th>000001.SS</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>^IXIC</th>\n",
       "      <th>^N100</th>\n",
       "      <th>^NDX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-17</th>\n",
       "      <td>193.424000</td>\n",
       "      <td>1.669500e+09</td>\n",
       "      <td>3.145176e+03</td>\n",
       "      <td>159.991000</td>\n",
       "      <td>194.753000</td>\n",
       "      <td>158.044000</td>\n",
       "      <td>193.424000</td>\n",
       "      <td>172.514333</td>\n",
       "      <td>1.669500e+09</td>\n",
       "      <td>1.805774e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1628.20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3219.791016</td>\n",
       "      <td>2459.500000</td>\n",
       "      <td>6320.350098</td>\n",
       "      <td>1010.400024</td>\n",
       "      <td>5845.819824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>234.391000</td>\n",
       "      <td>2.709260e+09</td>\n",
       "      <td>4.717765e+03</td>\n",
       "      <td>195.027000</td>\n",
       "      <td>267.986000</td>\n",
       "      <td>182.059000</td>\n",
       "      <td>234.391000</td>\n",
       "      <td>204.764931</td>\n",
       "      <td>2.709260e+09</td>\n",
       "      <td>2.188796e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3998.08</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3159.731934</td>\n",
       "      <td>2455.879883</td>\n",
       "      <td>6304.819824</td>\n",
       "      <td>1007.530029</td>\n",
       "      <td>5832.919922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-19</th>\n",
       "      <td>199.703000</td>\n",
       "      <td>2.328790e+09</td>\n",
       "      <td>6.290353e+03</td>\n",
       "      <td>234.941000</td>\n",
       "      <td>245.651000</td>\n",
       "      <td>191.745000</td>\n",
       "      <td>199.703000</td>\n",
       "      <td>225.754365</td>\n",
       "      <td>2.328790e+09</td>\n",
       "      <td>1.865361e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2808.81</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3181.402100</td>\n",
       "      <td>2463.850098</td>\n",
       "      <td>6363.240234</td>\n",
       "      <td>1004.760010</td>\n",
       "      <td>5898.399902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-20</th>\n",
       "      <td>227.265000</td>\n",
       "      <td>2.225000e+09</td>\n",
       "      <td>7.862941e+03</td>\n",
       "      <td>205.422000</td>\n",
       "      <td>233.904000</td>\n",
       "      <td>203.216000</td>\n",
       "      <td>227.265000</td>\n",
       "      <td>219.248451</td>\n",
       "      <td>2.225000e+09</td>\n",
       "      <td>2.123365e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1721.93</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3227.506104</td>\n",
       "      <td>2475.560059</td>\n",
       "      <td>6396.459961</td>\n",
       "      <td>1012.309998</td>\n",
       "      <td>5929.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-21</th>\n",
       "      <td>218.305000</td>\n",
       "      <td>1.006130e+09</td>\n",
       "      <td>9.435529e+03</td>\n",
       "      <td>226.061000</td>\n",
       "      <td>235.118000</td>\n",
       "      <td>213.010000</td>\n",
       "      <td>218.305000</td>\n",
       "      <td>224.663132</td>\n",
       "      <td>1.006130e+09</td>\n",
       "      <td>2.040171e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2523.11</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3236.587891</td>\n",
       "      <td>2467.399902</td>\n",
       "      <td>6383.049805</td>\n",
       "      <td>1005.869995</td>\n",
       "      <td>5905.600098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-08</th>\n",
       "      <td>1230.209202</td>\n",
       "      <td>1.628545e+10</td>\n",
       "      <td>2.666409e+06</td>\n",
       "      <td>1237.558858</td>\n",
       "      <td>1261.776012</td>\n",
       "      <td>1200.632216</td>\n",
       "      <td>1230.209202</td>\n",
       "      <td>1233.697254</td>\n",
       "      <td>1.628545e+10</td>\n",
       "      <td>1.494304e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>12672</td>\n",
       "      <td>17967380.49</td>\n",
       "      <td>46655</td>\n",
       "      <td>7.807354e+10</td>\n",
       "      <td>4.952661e+10</td>\n",
       "      <td>3380.370117</td>\n",
       "      <td>3888.260010</td>\n",
       "      <td>11503.610352</td>\n",
       "      <td>1169.170044</td>\n",
       "      <td>11977.950195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-10</th>\n",
       "      <td>1168.401611</td>\n",
       "      <td>1.098456e+10</td>\n",
       "      <td>2.671018e+06</td>\n",
       "      <td>1216.625268</td>\n",
       "      <td>1216.797657</td>\n",
       "      <td>1157.175540</td>\n",
       "      <td>1168.401611</td>\n",
       "      <td>1182.985909</td>\n",
       "      <td>1.098456e+10</td>\n",
       "      <td>1.419541e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>13205</td>\n",
       "      <td>19310139.95</td>\n",
       "      <td>40092</td>\n",
       "      <td>7.804470e+10</td>\n",
       "      <td>4.895357e+10</td>\n",
       "      <td>3360.735107</td>\n",
       "      <td>3884.599976</td>\n",
       "      <td>11514.050293</td>\n",
       "      <td>1162.010010</td>\n",
       "      <td>11993.354980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-11</th>\n",
       "      <td>1097.236515</td>\n",
       "      <td>1.206418e+10</td>\n",
       "      <td>2.672475e+06</td>\n",
       "      <td>1167.707855</td>\n",
       "      <td>1169.193825</td>\n",
       "      <td>1095.126569</td>\n",
       "      <td>1097.236515</td>\n",
       "      <td>1142.838904</td>\n",
       "      <td>1.206418e+10</td>\n",
       "      <td>1.333228e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>14355</td>\n",
       "      <td>17449920.08</td>\n",
       "      <td>43668</td>\n",
       "      <td>7.637071e+10</td>\n",
       "      <td>4.779272e+10</td>\n",
       "      <td>3341.100098</td>\n",
       "      <td>3880.939941</td>\n",
       "      <td>11524.490234</td>\n",
       "      <td>1154.849976</td>\n",
       "      <td>12008.759766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-12</th>\n",
       "      <td>1038.191695</td>\n",
       "      <td>1.258328e+10</td>\n",
       "      <td>2.674690e+06</td>\n",
       "      <td>1096.552881</td>\n",
       "      <td>1097.069843</td>\n",
       "      <td>1038.135642</td>\n",
       "      <td>1038.191695</td>\n",
       "      <td>1070.672908</td>\n",
       "      <td>1.258328e+10</td>\n",
       "      <td>1.261626e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>15676</td>\n",
       "      <td>18884615.57</td>\n",
       "      <td>45364</td>\n",
       "      <td>7.405698e+10</td>\n",
       "      <td>4.633532e+10</td>\n",
       "      <td>3307.219971</td>\n",
       "      <td>3851.949951</td>\n",
       "      <td>11420.889648</td>\n",
       "      <td>1162.000000</td>\n",
       "      <td>11926.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-13</th>\n",
       "      <td>1113.587153</td>\n",
       "      <td>1.830259e+10</td>\n",
       "      <td>2.676918e+06</td>\n",
       "      <td>1038.186585</td>\n",
       "      <td>1113.587153</td>\n",
       "      <td>1019.220319</td>\n",
       "      <td>1113.587153</td>\n",
       "      <td>1066.349852</td>\n",
       "      <td>1.830259e+10</td>\n",
       "      <td>1.353383e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>13972</td>\n",
       "      <td>20053088.85</td>\n",
       "      <td>43598</td>\n",
       "      <td>7.241011e+10</td>\n",
       "      <td>4.501321e+10</td>\n",
       "      <td>3279.600098</td>\n",
       "      <td>3779.669922</td>\n",
       "      <td>11056.549805</td>\n",
       "      <td>1169.270020</td>\n",
       "      <td>11523.910156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1778 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              price_usd    volume_usd  twitter_followers  \\\n",
       "datetime                                                   \n",
       "2017-07-17   193.424000  1.669500e+09       3.145176e+03   \n",
       "2017-07-18   234.391000  2.709260e+09       4.717765e+03   \n",
       "2017-07-19   199.703000  2.328790e+09       6.290353e+03   \n",
       "2017-07-20   227.265000  2.225000e+09       7.862941e+03   \n",
       "2017-07-21   218.305000  1.006130e+09       9.435529e+03   \n",
       "...                 ...           ...                ...   \n",
       "2022-07-08  1230.209202  1.628545e+10       2.666409e+06   \n",
       "2022-07-10  1168.401611  1.098456e+10       2.671018e+06   \n",
       "2022-07-11  1097.236515  1.206418e+10       2.672475e+06   \n",
       "2022-07-12  1038.191695  1.258328e+10       2.674690e+06   \n",
       "2022-07-13  1113.587153  1.830259e+10       2.676918e+06   \n",
       "\n",
       "            daily_opening_price_usd  daily_high_price_usd  \\\n",
       "datetime                                                    \n",
       "2017-07-17               159.991000            194.753000   \n",
       "2017-07-18               195.027000            267.986000   \n",
       "2017-07-19               234.941000            245.651000   \n",
       "2017-07-20               205.422000            233.904000   \n",
       "2017-07-21               226.061000            235.118000   \n",
       "...                             ...                   ...   \n",
       "2022-07-08              1237.558858           1261.776012   \n",
       "2022-07-10              1216.625268           1216.797657   \n",
       "2022-07-11              1167.707855           1169.193825   \n",
       "2022-07-12              1096.552881           1097.069843   \n",
       "2022-07-13              1038.186585           1113.587153   \n",
       "\n",
       "            daily_low_price_usd  daily_closing_price_usd  daily_avg_price_usd  \\\n",
       "datetime                                                                        \n",
       "2017-07-17           158.044000               193.424000           172.514333   \n",
       "2017-07-18           182.059000               234.391000           204.764931   \n",
       "2017-07-19           191.745000               199.703000           225.754365   \n",
       "2017-07-20           203.216000               227.265000           219.248451   \n",
       "2017-07-21           213.010000               218.305000           224.663132   \n",
       "...                         ...                      ...                  ...   \n",
       "2022-07-08          1200.632216              1230.209202          1233.697254   \n",
       "2022-07-10          1157.175540              1168.401611          1182.985909   \n",
       "2022-07-11          1095.126569              1097.236515          1142.838904   \n",
       "2022-07-12          1038.135642              1038.191695          1070.672908   \n",
       "2022-07-13          1019.220319              1113.587153          1066.349852   \n",
       "\n",
       "            daily_trading_volume_usd  marketcap_usd  ...  eth_NFT_buyers  \\\n",
       "datetime                                             ...                   \n",
       "2017-07-17              1.669500e+09   1.805774e+10  ...               5   \n",
       "2017-07-18              2.709260e+09   2.188796e+10  ...              11   \n",
       "2017-07-19              2.328790e+09   1.865361e+10  ...               5   \n",
       "2017-07-20              2.225000e+09   2.123365e+10  ...               4   \n",
       "2017-07-21              1.006130e+09   2.040171e+10  ...               6   \n",
       "...                              ...            ...  ...             ...   \n",
       "2022-07-08              1.628545e+10   1.494304e+11  ...           12672   \n",
       "2022-07-10              1.098456e+10   1.419541e+11  ...           13205   \n",
       "2022-07-11              1.206418e+10   1.333228e+11  ...           14355   \n",
       "2022-07-12              1.258328e+10   1.261626e+11  ...           15676   \n",
       "2022-07-13              1.830259e+10   1.353383e+11  ...           13972   \n",
       "\n",
       "            total_NFT_sales  total_NFT_buyers     total_TVL       eth_TVL  \\\n",
       "datetime                                                                    \n",
       "2017-07-17          1628.20                 5  0.000000e+00  0.000000e+00   \n",
       "2017-07-18          3998.08                11  0.000000e+00  0.000000e+00   \n",
       "2017-07-19          2808.81                 5  0.000000e+00  0.000000e+00   \n",
       "2017-07-20          1721.93                 4  0.000000e+00  0.000000e+00   \n",
       "2017-07-21          2523.11                 6  0.000000e+00  0.000000e+00   \n",
       "...                     ...               ...           ...           ...   \n",
       "2022-07-08      17967380.49             46655  7.807354e+10  4.952661e+10   \n",
       "2022-07-10      19310139.95             40092  7.804470e+10  4.895357e+10   \n",
       "2022-07-11      17449920.08             43668  7.637071e+10  4.779272e+10   \n",
       "2022-07-12      18884615.57             45364  7.405698e+10  4.633532e+10   \n",
       "2022-07-13      20053088.85             43598  7.241011e+10  4.501321e+10   \n",
       "\n",
       "              000001.SS        ^GSPC         ^IXIC        ^N100          ^NDX  \n",
       "datetime                                                                       \n",
       "2017-07-17  3219.791016  2459.500000   6320.350098  1010.400024   5845.819824  \n",
       "2017-07-18  3159.731934  2455.879883   6304.819824  1007.530029   5832.919922  \n",
       "2017-07-19  3181.402100  2463.850098   6363.240234  1004.760010   5898.399902  \n",
       "2017-07-20  3227.506104  2475.560059   6396.459961  1012.309998   5929.580078  \n",
       "2017-07-21  3236.587891  2467.399902   6383.049805  1005.869995   5905.600098  \n",
       "...                 ...          ...           ...          ...           ...  \n",
       "2022-07-08  3380.370117  3888.260010  11503.610352  1169.170044  11977.950195  \n",
       "2022-07-10  3360.735107  3884.599976  11514.050293  1162.010010  11993.354980  \n",
       "2022-07-11  3341.100098  3880.939941  11524.490234  1154.849976  12008.759766  \n",
       "2022-07-12  3307.219971  3851.949951  11420.889648  1162.000000  11926.839844  \n",
       "2022-07-13  3279.600098  3779.669922  11056.549805  1169.270020  11523.910156  \n",
       "\n",
       "[1778 rows x 43 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 23:28:37.293004: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 8s 140ms/step - loss: 2472089.2500 - mean_absolute_percentage_error: 70.6669 - val_loss: 2329602.5000 - val_mean_absolute_percentage_error: 61.6696\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 4s 120ms/step - loss: 1867735.2500 - mean_absolute_percentage_error: 44.2251 - val_loss: 1616584.6250 - val_mean_absolute_percentage_error: 36.7221\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 4s 134ms/step - loss: 1209444.0000 - mean_absolute_percentage_error: 28.8137 - val_loss: 926456.8125 - val_mean_absolute_percentage_error: 24.1266\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 4s 129ms/step - loss: 651208.8750 - mean_absolute_percentage_error: 20.5469 - val_loss: 415814.8750 - val_mean_absolute_percentage_error: 21.5939\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 5s 140ms/step - loss: 268432.6250 - mean_absolute_percentage_error: 14.4514 - val_loss: 131654.2500 - val_mean_absolute_percentage_error: 13.5104\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 4s 130ms/step - loss: 85726.4844 - mean_absolute_percentage_error: 11.3028 - val_loss: 50137.3633 - val_mean_absolute_percentage_error: 12.4362\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 4s 129ms/step - loss: 35857.1680 - mean_absolute_percentage_error: 9.2595 - val_loss: 31891.9629 - val_mean_absolute_percentage_error: 12.5178\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 23710.5449 - mean_absolute_percentage_error: 9.2126 - val_loss: 19587.1504 - val_mean_absolute_percentage_error: 6.4997\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 4s 132ms/step - loss: 20719.5625 - mean_absolute_percentage_error: 8.7066 - val_loss: 13947.3369 - val_mean_absolute_percentage_error: 6.7782\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 4s 130ms/step - loss: 18045.5977 - mean_absolute_percentage_error: 8.4653 - val_loss: 23217.8730 - val_mean_absolute_percentage_error: 9.2978\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 16413.6699 - mean_absolute_percentage_error: 8.1831 - val_loss: 27034.8359 - val_mean_absolute_percentage_error: 7.3568\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 17096.5977 - mean_absolute_percentage_error: 8.3761 - val_loss: 14148.4082 - val_mean_absolute_percentage_error: 7.0771\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 4s 132ms/step - loss: 15289.4512 - mean_absolute_percentage_error: 8.2463 - val_loss: 14649.0518 - val_mean_absolute_percentage_error: 6.4892\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 4s 134ms/step - loss: 16990.1387 - mean_absolute_percentage_error: 7.5926 - val_loss: 16760.1816 - val_mean_absolute_percentage_error: 9.3578\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None), dtype=tf.float32, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 43).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "551.9666962808463"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(data = data, nb_sequences=2000, nb_days=21, plot_history=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 8s 164ms/step - loss: 2462288.5000 - val_loss: 2298478.2500\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 4s 133ms/step - loss: 1718887.6250 - val_loss: 1463196.5000\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 4s 132ms/step - loss: 981890.2500 - val_loss: 749334.1875\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 4s 132ms/step - loss: 437806.3750 - val_loss: 341611.1250\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 175199.2031 - val_loss: 114462.8438\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 57121.8164 - val_loss: 33481.1875\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 27926.2246 - val_loss: 20596.3320\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 4s 137ms/step - loss: 22599.9590 - val_loss: 59097.1367\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 23062.9941 - val_loss: 22803.4531\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 5s 139ms/step - loss: 19885.6797 - val_loss: 14850.4082\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 4s 128ms/step - loss: 18552.7949 - val_loss: 28075.6621\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 4s 125ms/step - loss: 18817.8691 - val_loss: 16156.5498\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 17725.3242 - val_loss: 13561.6309\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 15426.7119 - val_loss: 13513.1689\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 16946.5078 - val_loss: 46076.3477\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 16065.1523 - val_loss: 11476.8145\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 4s 133ms/step - loss: 18005.6543 - val_loss: 29107.4883\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 4s 133ms/step - loss: 19572.9746 - val_loss: 15274.8418\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 4s 134ms/step - loss: 15663.7344 - val_loss: 16925.1602\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 4s 127ms/step - loss: 13544.1777 - val_loss: 13746.8838\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 4s 134ms/step - loss: 13353.5039 - val_loss: 43042.8086\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None), dtype=tf.float32, name='normalization_1_input'), name='normalization_1_input', description=\"created by layer 'normalization_1_input'\"), but it was called on an input with incompatible shape (None, 43).\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/training.py\", line 864, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/training.py\", line 957, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 438, in update_state\n        self.build(y_pred, y_true)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 358, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 484, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 484, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 503, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/metrics.py\", line 4266, in get\n        raise ValueError(\n\n    ValueError: Could not interpret metric identifier: 11\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000028?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m nb_days \u001b[39min\u001b[39;00m nb_days_grid:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000028?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m nb_sequences \u001b[39min\u001b[39;00m nb_sequences_grid:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000028?line=5'>6</a>\u001b[0m         res \u001b[39m=\u001b[39m train_model(data \u001b[39m=\u001b[39;49m data,nb_sequences\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m, nb_days\u001b[39m=\u001b[39;49mnb_days)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000028?line=6'>7</a>\u001b[0m         MAPE\u001b[39m.\u001b[39mappend((nb_days, nb_sequences, res))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000028?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFor \u001b[39m\u001b[39m{\u001b[39;00mnb_sequences\u001b[39m}\u001b[39;00m\u001b[39m sequences and \u001b[39m\u001b[39m{\u001b[39;00mnb_days\u001b[39m}\u001b[39;00m\u001b[39m days of observation, the MAPE is of \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m %\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb Cell 14'\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(data, nb_sequences, nb_days, plot_history)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=57'>58</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=58'>59</a>\u001b[0m             optimizer\u001b[39m=\u001b[39mRMSprop(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=59'>60</a>\u001b[0m             metrics\u001b[39m=\u001b[39mMAPE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=62'>63</a>\u001b[0m es \u001b[39m=\u001b[39m callbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=64'>65</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train_pad,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=65'>66</a>\u001b[0m             np\u001b[39m.\u001b[39;49marray(y_train),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=66'>67</a>\u001b[0m             epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=67'>68</a>\u001b[0m             batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=68'>69</a>\u001b[0m             validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=69'>70</a>\u001b[0m             callbacks\u001b[39m=\u001b[39;49m[es],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=70'>71</a>\u001b[0m             verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=72'>73</a>\u001b[0m \u001b[39mif\u001b[39;00m plot_history:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000029?line=73'>74</a>\u001b[0m     plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mmean_absolute_percentage_error\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/training.py\", line 864, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/training.py\", line 957, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 438, in update_state\n        self.build(y_pred, y_true)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 358, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 484, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 484, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 503, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/metrics.py\", line 4266, in get\n        raise ValueError(\n\n    ValueError: Could not interpret metric identifier: 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nb_days_grid = [11, 21, 41, 61, 81, 121, 151]\n",
    "nb_sequences_grid = [1000, 2000, 4000]\n",
    "MAPE = []\n",
    "for nb_days in nb_days_grid:\n",
    "    for nb_sequences in nb_sequences_grid:\n",
    "        res = train_model(data = data,nb_sequences=2000, nb_days=nb_days)\n",
    "        MAPE.append((nb_days, nb_sequences, res))\n",
    "    \n",
    "    print(f'For {nb_sequences} sequences and {nb_days} days of observation, the MAPE is of {res:.0f} %')\n",
    "\n",
    "MAPE\n",
    "\n",
    "x = [res[0] for res in MAPE] # n_days\n",
    "y = [res[1] for res in MAPE] # n_seq\n",
    "c = [res[2] for res in MAPE] # MAPE  \n",
    "plt.scatter(x, y, c=c, norm=matplotlib.colors.Normalize(vmin=20, vmax=50, clip=False), cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def repeat_evaluate(data, config, n_test, n_repeats=10):\n",
    "\t# convert config to a key\n",
    "\tkey = str(config)\n",
    "\t# fit and evaluate the model n times\n",
    "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "\t# summarize score\n",
    "\tresult = mean(scores)\n",
    "\tprint('> Model[%s] %.3f' % (key, result))\n",
    "\treturn (key, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define config\n",
    "'''\n",
    "A list of index offsets in the prior observations \n",
    "relative to the time to be forecasted that will be used as the prediction. \n",
    "For example, 12 will use the observation 12 months ago (-12) relative to the time to be forecasted.\n",
    "'''\n",
    "cfg_list = [1, 6, 12, 24, 36]\n",
    "\n",
    "ratio=0.95\n",
    "len_ = int(ratio * data.shape[0])\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, len_):\n",
    "\t# evaluate configs\n",
    "\tscores = [score_model(data, len_, cfg) for cfg in cfg_list]\n",
    "\t# sort configs by error, asc\n",
    "\tscores.sort(key=lambda tup: tup[1])\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../raw_data/data_advanced.csv', index_col = 'datetime') # TO RUN LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    ###########################\n",
    "    # 1. Define architecture  #\n",
    "    ###########################    \n",
    "         # Notice that we don't specify the input shape yet...\n",
    "         # ... as we don't know the shape post-preprocessing!\n",
    "         # One consequence is that here, you cannot yet print \n",
    "         # the model's summary. It will be known after fitting it\n",
    "         # to X_train_preprocessed, y_train\n",
    "        \n",
    "    normalizer = Normalization()\n",
    "    normalizer.adapt(X_train_pad)\n",
    "    model = Sequential()\n",
    "    model.add(normalizer)\n",
    "    model.add(layers.Masking(mask_value = -1))\n",
    "    model.add(layers.LSTM(40, activation='tanh')) # GS N UNITS\n",
    "    model.add(layers.Dense(40, activation='relu')) # GS N UNITS\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "    ###########################    \n",
    "    # 2. Compile model        #\n",
    "    ###########################    \n",
    "    model.compile(loss='mse', \n",
    "                    optimizer=RMSprop(learning_rate=0.01), \n",
    "                    metrics=MAPE)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/592h1xbs6sb54xxswdffplgc0000gn/T/ipykernel_44942/1020509451.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  disguised_deep_model = KerasRegressor(build_fn = create_model(),\n"
     ]
    }
   ],
   "source": [
    "disguised_deep_model = KerasRegressor(build_fn = create_model(), \n",
    "                                       epochs = 10, \n",
    "                                       batch_size = 32, \n",
    "                                       verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = split_tr_te(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = extract_xy_tr_te(train=data_train,\n",
    "                                    test=data_test)\n",
    "X_train_pad = padding_seq(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 00:17:55.707285: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://21a6a90b-dbd9-4212-892f-d0d0889aa929/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://21a6a90b-dbd9-4212-892f-d0d0889aa929/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x1a1fa2850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "2022-07-16 00:18:01.524247: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:01.540904: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:01.697273: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:01.713463: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:01.827540: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:01.847742: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f33f7bff-1f6d-4cf7-9a74-b291f7ec78c3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f33f7bff-1f6d-4cf7-9a74-b291f7ec78c3/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x1a1fa2850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "2022-07-16 00:18:09.275903: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:09.527866: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:10.717398: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:10.734915: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:10.948653: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:10.968266: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://b3423342-e58f-47b9-bbc1-f5d971b9582a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://b3423342-e58f-47b9-bbc1-f5d971b9582a/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x1a1fa2850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "2022-07-16 00:18:17.946245: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:18.744265: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:18.845507: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:19.269537: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:19.429529: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:19.445788: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://32390560-5c3e-4566-af3e-06e2d21bb6a4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://32390560-5c3e-4566-af3e-06e2d21bb6a4/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x1a6cbdee0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
      "2022-07-16 00:18:34.350823: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d68fc200-3f97-442b-8107-57e73f47c1f0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d68fc200-3f97-442b-8107-57e73f47c1f0/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x1a7c065b0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "2022-07-16 00:18:36.860154: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:36.891675: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:37.371251: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:37.421772: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:39.089787: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:39.113815: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
      "2022-07-16 00:18:46.057453: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7f4e59b2-0b48-47b9-9ad7-486bdaaf3fc0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7f4e59b2-0b48-47b9-9ad7-486bdaaf3fc0/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x1a99a3a30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "2022-07-16 00:18:49.894486: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:49.924460: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:50.004342: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:50.040025: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:50.248264: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:50.277028: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:55.614181: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-16 00:18:58.057821: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:58.073473: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:58.161674: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:58.176893: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:58.437942: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-07-16 00:18:58.454620: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/wrappers/scikit_learn.py\", line 152, in fit\n    self.model = self.build_fn(\n  File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 3094, in _split_out_first_arg\n    raise ValueError(\nValueError: The first argument to `Layer.call` must always be passed.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000021?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_score\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000021?line=2'>3</a>\u001b[0m \u001b[39m# $CHALLENGIFY_BEGIN\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000021?line=3'>4</a>\u001b[0m cross_val_score(disguised_deep_model, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000021?line=4'>5</a>\u001b[0m                 X_train_pad, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000021?line=5'>6</a>\u001b[0m                 y_train, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000021?line=6'>7</a>\u001b[0m                 cv \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonhou/code/mtorygreen/crypto_analysis/notebooks/deep_grid_search.ipynb#ch0000021?line=7'>8</a>\u001b[0m                 n_jobs \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[0;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/wrappers/scikit_learn.py\", line 152, in fit\n    self.model = self.build_fn(\n  File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/Users/jasonhou/.pyenv/versions/3.8.12/envs/Crypto-Analysis/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 3094, in _split_out_first_arg\n    raise ValueError(\nValueError: The first argument to `Layer.call` must always be passed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# $CHALLENGIFY_BEGIN\n",
    "cross_val_score(disguised_deep_model, \n",
    "                X_train_pad, \n",
    "                y_train, \n",
    "                cv = 3, \n",
    "                n_jobs = -1)\n",
    "# $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(disguised_deep_model)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_grid(activation = 'relu', \n",
    "                      optimizer = 'rmsprop'):\n",
    "    # create model\n",
    "    normalizer = Normalization()\n",
    "    normalizer.adapt(X_train_pad)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(normalizer)\n",
    "    model.add(layers.Masking(mask_value=-1))\n",
    "    model.add(layers.LSTM(40, activation='tanh')) # GS N UNITS\n",
    "    model.add(layers.Dense(40, activation='relu')) # GS N UNITS\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='mse', \n",
    "                    optimizer=RMSprop(learning_rate=0.01), \n",
    "                    metrics=MAPE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = KerasRegressor(\n",
    "                    build_fn = create_model_grid,\n",
    "                    epochs = 10,\n",
    "                    batch_size = 32,\n",
    "                    verbose = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('Crypto-Analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14b22400082d8a78f9dc64d24728899008324d609f6ec0963baa091061841b0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
